{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1309d51c",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "\n",
    "1) Import Libraries and Data\n",
    "\n",
    "2) Describe products data\n",
    "\n",
    "3) Check for missing data in products\n",
    "\n",
    "4) Check for duplicate data in products\n",
    "\n",
    "5) Check for mixed data types in orders data\n",
    "\n",
    "6) Check for missing values in orders data\n",
    "\n",
    "7) Check for duplicate data in orders\n",
    "\n",
    "8) Export data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27edf5e7",
   "metadata": {},
   "source": [
    "### 1) \n",
    "Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b25d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28401d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path to data folder\n",
    "path = r'C:\\Users\\Owner\\Documents\\Career Foundry\\Tasks\\Data Immersion Tasks\\Instacart Project\\2 Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9829ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import original product data as df_prods and wrangled orders data as df_ords\n",
    "df_prods = pd.read_csv(os.path.join(path, 'original data','products.csv'))\n",
    "df_ords = pd.read_csv(os.path.join(path, 'prepared data','orders_wrangled.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9041a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "##remove the extra index column from df_ords\n",
    "df_ords = df_ords.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90301be",
   "metadata": {},
   "source": [
    "## 2) Run the df.describe() function on your df_prods dataframe. \n",
    "Using your new knowledge about how to interpret the output of this function, share in a markdown cell whether anything about the data looks off or should be investigated further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c85fe135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department_id</th>\n",
       "      <th>prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49693.000000</td>\n",
       "      <td>49693.000000</td>\n",
       "      <td>49693.000000</td>\n",
       "      <td>49693.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24844.345139</td>\n",
       "      <td>67.770249</td>\n",
       "      <td>11.728433</td>\n",
       "      <td>9.994136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14343.717401</td>\n",
       "      <td>38.316774</td>\n",
       "      <td>5.850282</td>\n",
       "      <td>453.519686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12423.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24845.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37265.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>11.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49688.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         product_id      aisle_id  department_id        prices\n",
       "count  49693.000000  49693.000000   49693.000000  49693.000000\n",
       "mean   24844.345139     67.770249      11.728433      9.994136\n",
       "std    14343.717401     38.316774       5.850282    453.519686\n",
       "min        1.000000      1.000000       1.000000      1.000000\n",
       "25%    12423.000000     35.000000       7.000000      4.100000\n",
       "50%    24845.000000     69.000000      13.000000      7.100000\n",
       "75%    37265.000000    100.000000      17.000000     11.200000\n",
       "max    49688.000000    134.000000      21.000000  99999.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run describe function on df_prods\n",
    "df_prods.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80c5c33",
   "metadata": {},
   "source": [
    "As a confirmation I would like to make sure that the physical store does have 134 aisles to match the max in aisle_id. Similarly I would confirm there are 21 departments to match the max in deparment_id.\n",
    "\n",
    "The max value of 99999 in prices seems suspect as based on the min and quartile values I would expect the max to be in the 12-20 range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d19813",
   "metadata": {},
   "source": [
    "### 3)\n",
    "Check for missing values in products data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3618e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id        0\n",
       "product_name     16\n",
       "aisle_id          0\n",
       "department_id     0\n",
       "prices            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding sum of missing values by column in df_prods\n",
    "df_prods.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2caf7ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a subset of the df_prods dataframe called df_nan that only has the 16 missing product_name values\n",
    "df_nan = df_prods[df_prods['product_name'].isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f77c888c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49693, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check size of df_prods\n",
    "df_prods.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11f8530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a subset of the df_prods dataframe called df_prods_clean that only has NO missing product_name values\n",
    "df_prods_clean = df_prods[df_prods['product_name'].isnull() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1edab7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49677, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check size of df_prods_clean\n",
    "df_prods_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbaa69d",
   "metadata": {},
   "source": [
    "### 4) \n",
    "Check products data for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a998b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new data frame df_dups of just the duplicate rows in df_prods_clean\n",
    "df_dups = df_prods_clean[df_prods_clean.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96390994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department_id</th>\n",
       "      <th>prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>462</td>\n",
       "      <td>Fiber 4g Gummy Dietary Supplement</td>\n",
       "      <td>70</td>\n",
       "      <td>11</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18459</th>\n",
       "      <td>18458</td>\n",
       "      <td>Ranger IPA</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26810</th>\n",
       "      <td>26808</td>\n",
       "      <td>Black House Coffee Roasty Stout Beer</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35309</th>\n",
       "      <td>35306</td>\n",
       "      <td>Gluten Free Organic Peanut Butter &amp; Chocolate ...</td>\n",
       "      <td>121</td>\n",
       "      <td>14</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35495</th>\n",
       "      <td>35491</td>\n",
       "      <td>Adore Forever Body Wash</td>\n",
       "      <td>127</td>\n",
       "      <td>11</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id                                       product_name  \\\n",
       "462           462                  Fiber 4g Gummy Dietary Supplement   \n",
       "18459       18458                                         Ranger IPA   \n",
       "26810       26808               Black House Coffee Roasty Stout Beer   \n",
       "35309       35306  Gluten Free Organic Peanut Butter & Chocolate ...   \n",
       "35495       35491                            Adore Forever Body Wash   \n",
       "\n",
       "       aisle_id  department_id  prices  \n",
       "462          70             11     4.8  \n",
       "18459        27              5     9.2  \n",
       "26810        27              5    13.4  \n",
       "35309       121             14     6.8  \n",
       "35495       127             11     9.9  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ee587f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates from df_prods_clean and create new dataframe df_prods_clean_no_dups\n",
    "df_prods_clean_no_dups = df_prods_clean.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16c1b4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49672, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prods_clean_no_dups.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09638f03",
   "metadata": {},
   "source": [
    "### 5) \n",
    "Check for mixed-type data in your df_ords dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134bba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search df_ords for columns that have mixed data types\n",
    "for col in df_ords.columns.tolist():\n",
    "  weird = (df_ords[[col]].applymap(type) != df_ords[[col]].iloc[0].apply(type)).any(axis = 1)\n",
    "  if len (df_ords[weird]) > 0:\n",
    "    print (col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae424463",
   "metadata": {},
   "source": [
    "No results show, suggesting that df_ords has no mixed type columns if this was run correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ac10d",
   "metadata": {},
   "source": [
    "## 6)\n",
    "Run a check for missing values in your df_ords dataframe.\n",
    "In a markdown cell, report your findings and propose an explanation for any missing values you find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e523fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find count of missing values in df_ords by column\n",
    "df_ords.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a122e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ords.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2bda1e",
   "metadata": {},
   "source": [
    "In the data frame df_ords there are 206209 missing values in the column 'days_since_prior_order'. This is the only column with missing data.\n",
    "This count likely represents customers that have only made a single order. They will have no second order date value to complete the calucation for this column and would be missing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1108e",
   "metadata": {},
   "source": [
    "Address the missing values using an appropriate method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0152070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data frame df_ords_miss that only has the rows from df_ords with null values in 'days_since_prior_order' column\n",
    "df_ords_miss = df_ords[df_ords['days_since_prior_order'].isnull() ==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa7b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use describe on df_ords_miss to show that order number is always 1 for the null values\n",
    "df_ords_miss.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af190bb",
   "metadata": {},
   "source": [
    "I chose to do nothing.\n",
    "\n",
    "The first of 3 options I thought of was to create a new column that uses string values to define an order as some variation of \"First\" or \"Repeat\". I thought this was not appropriate as the order_number column already can provide this information and this would be duplicate data.\n",
    "\n",
    "The second option was to replace the null values in 'days_since_prior_order' with some string value to denote 'First' order. I chose not to do this because I dotn want to put string values in the floating point data values.\n",
    "\n",
    "The third option was to replace the null values in 'days_since_prior_order' with 0.0. I felt this was innapropriate as this could mean the same thing as a second order that was placed on the same day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6299f6",
   "metadata": {},
   "source": [
    "## 7) \n",
    "Run a check for duplicate values in your df_ords data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03e4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new data frame df_ords_dupes that returns rows of df_rds that are duplicates across all columns\n",
    "df_ords_dupes = df_ords[df_ords.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at df_ords_dupes to see which rows are duplcicates in df_ords\n",
    "df_ords_dupes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69110e05",
   "metadata": {},
   "source": [
    "No duplicate values found in df_ords. Likely due to the order_number column keeping things unique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288dfcf3",
   "metadata": {},
   "source": [
    "## 8) \n",
    "Export your final, cleaned df_prods and df_ords data as “.csv” files in your “Prepared Data” folder and give them appropriate, succinct names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cf9a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export df_ords data as 'orders_cleaned.csv'\n",
    "df_ords.to_csv(os.path.join(path, 'prepared data','orders_cleaned.csv' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c822c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the cleaned product data during the task instruction time as 'products_cleaned.csv'\n",
    "df_prods_clean_no_dups.to_csv(os.path.join(path, 'prepared data','products_cleaned.csv' ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
